
# Python Ollama Starter

A simple Flask app customized to work with LLM models using Ollama


## Run Locally

Clone the project

```bash
  git clone https://github.com/zakerby/python-ollama-starter my-project
```

Go to the project directory

```bash
  cd my-project
```

Run Docker Compose

```bash
  docker-compose up -d
```

